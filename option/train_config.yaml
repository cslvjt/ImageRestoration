# cmd: CUDA_VISIBLE_DEVICES=6,7 accelerate launch --num_processes 2 --main_process_port 12345 train.py --name LWDNet --config config/LWDNet.yaml
seed: 100 # 随时种子
dataset:
  train:
    dataroot_gt: /data1/lvjiangtao/lvjiangtao/dataset/GoPro_train_latest/train/gt # 训练数据GT
    dataroot_lq: /data1/lvjiangtao/lvjiangtao/dataset/GoPro_train_latest/train/blur # 训练数据LQ
    
    patch_size: 256 # 训练时patchsize大小
    num_workers: 8 # 数据读取时单个worker
    batch_size: 12 # 单个GPU的batchsize大小
    scale: 1 # 用于超分任务，指定lq与hq的超分倍数
    use_hflip: True # 数据增强策略
    use_rot: True
  validation:
    dataroot_gt: /data1/lvjiangtao/lvjiangtao/dataset/GoPro_train_latest/testmini/gt # 测试数据GT
    dataroot_lq: /data1/lvjiangtao/lvjiangtao/dataset/GoPro_train_latest/testmini/blur # 测试数据LQ

# 模型超参设定
net:
  num_res: [8,12,16]
  base_channel: 32

train:
  iters: 300000 # 训练总迭代次数
  resume_path:  # 默认为None，当指定权重位置时，模型将从该权重继续训练

  # 设置训练损失函数
  L1loss:
    weight: 1
    reduction: mean
  FFTloss:
    weight: 0.1
    reduction: mean
  
  # 指定优化器
  optimizer:
    type: Adam
    lr: !!float 1e-3
    weight_decay: 0
    betas: [0.9,0.99]
  # 指定调度器
  scheduler:
    type: CosineAnnealingLR
    eta_min: !!float 1e-7

val:
  save_freq: 5000
  val_freq : 5000
  print_freq: 1000